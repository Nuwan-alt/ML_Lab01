# -*- coding: utf-8 -*-
"""190394R_Lab01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fzY6qaknQ8A6yG4Vy3WcPzXxmvm9ih6A

## MAIN
"""



from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %ls
# %pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/lab_01'

import pandas as pd
import numpy as np

# Labes
L1 = 'label_1'
L2 = 'label_2'
L3 = 'label_3'
L4 = 'label_4'

LABELS = [L1,L2,L3,L4]
AGE_LABEL = L2
FEATURES = [f"feature_{i}" for i in range (1,257)]

"""Import csv files

"""

train_df = pd.read_csv("train.csv")
valid_df = pd.read_csv("valid.csv")
test_df = pd.read_csv("test.csv")

"""Data segmentation and drop null values"""

from sklearn.preprocessing import StandardScaler
x_train = {}
x_valid = {}
y_train = {}
y_valid = {}
x_test = {}

for target_label in LABELS:
  tr_df = train_df[train_df['label_2'].notna()] if target_label == 'label_2' else train_df
  vl_df = valid_df[valid_df['label_2'].notna()] if target_label == 'label_2' else valid_df
  test_df = test_df
  scaler = StandardScaler()

  x_train[target_label] = pd.DataFrame(scaler.fit_transform(tr_df.drop(LABELS, axis = 1)), columns=FEATURES)
  y_train[target_label] = tr_df[target_label]

  x_valid[target_label] = pd.DataFrame(scaler.transform(vl_df.drop(LABELS, axis = 1)), columns=FEATURES)
  y_valid[target_label] = vl_df[target_label]

  x_test[target_label] = pd.DataFrame(scaler.transform(vl_df.drop(LABELS, axis = 1)), columns=FEATURES)

"""# Label_1"""

from sklearn import svm

clf = svm.SVC(kernel='linear', class_weight='balanced')
clf.fit(x_train[L1], y_train[L1])

from sklearn import metrics

y_pred = clf.predict(x_valid[L1])
y_pred_test_before = clf.predict(x_test[L1])

"""## Accuracy Before Feature Engineering"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L1], y_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L1], y_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L1], y_pred,average='weighted')}")

from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(f_classif, k=100)
x_new = selector.fit_transform(x_train[L1], y_train[L1])
print(x_new.shape)

clf = svm.SVC(kernel='linear' )
clf.fit(x_new, y_train[L1])

y_new_pred = clf.predict(selector.transform(x_valid[L1]))

"""## Accuracy After Feature Engineering - SelectKBest"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L1], y_new_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L1], y_new_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L1], y_new_pred,average='weighted')}")

from sklearn.decomposition import PCA
pca = PCA(n_components = 0.95, svd_solver ='full')
pca.fit(x_train[L1])
x_train_trans = pd.DataFrame(pca.transform(x_train[L1]))
x_valid_trans = pd.DataFrame(pca.transform(x_valid[L1]))
x_test_pca = pca.transform(x_test[L1])

print(x_train_trans.shape, x_valid_trans.shape)

clf = svm.SVC(kernel='linear' )
clf.fit(x_train_trans, y_train[L1])

y_new_trans = clf.predict(x_valid_trans)

y_pred_test_after = clf.predict(x_test_pca)
print('Predicted labels after feature engineering:', y_pred_test_after)

output_df = pd.DataFrame({
    'Predicted labels before feature engineering': y_pred_test_before,
    'Predicted labels after feature engineering': y_pred_test_after,
    'No. of new features': x_test_pca.shape[1]
})


for i in range(x_test_pca.shape[1]):
  output_df[f'New feature {i+1}'] = x_test_pca[:, i]

output_df.head()

# Save the DataFrame to the specified CSV file path
output_df.to_csv(f"190394R_label_1.csv", index=False)

"""## Accuracy After Feature Engineering - PCA"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L1], y_new_trans)}")
print(f"Precision: {metrics.precision_score(y_valid[L1], y_new_trans, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L1], y_new_trans,average='weighted')}")

"""# Label_2"""

from sklearn.neighbors import KNeighborsClassifier
k = 5  # Number of neighbors
knn_classifier = KNeighborsClassifier(n_neighbors=k)

knn_classifier.fit(x_train[L2], y_train[L2])

y_pred = knn_classifier.predict(x_valid[L2])
y_pred_test_before = knn_classifier.predict(x_test[L2])

"""## Accuracy Before Feature Engineering"""

from sklearn import metrics

print(f"Accuracy: {metrics.accuracy_score(y_valid[L2], y_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L2], y_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L2], y_pred,average='weighted')}")

from sklearn.decomposition import PCA
pca = PCA(n_components = 0.85, svd_solver ='full')
pca.fit(x_train[L2])
x_train_trans = pd.DataFrame(pca.transform(x_train[L2]))
x_valid_trans = pd.DataFrame(pca.transform(x_valid[L2]))
x_test_pca = pca.transform(x_test[L2])

print(x_train_trans.shape, x_valid_trans.shape)

knn_classifier.fit(x_train_trans, y_train[L2])

y_pred = knn_classifier.predict(x_valid_trans)

y_pred_test_after = knn_classifier.predict(x_test_pca)
print('Predicted labels after feature engineering:', y_pred_test_after)

output_df = pd.DataFrame({
    'Predicted labels before feature engineering': y_pred_test_before,
    'Predicted labels after feature engineering': y_pred_test_after,
    'No. of new features': x_test_pca.shape[1]
})


for i in range(x_test_pca.shape[1]):
  output_df[f'New feature {i+1}'] = x_test_pca[:, i]

output_df.head()

# Save the DataFrame to the specified CSV file path
output_df.to_csv(f"190394R_label_2.csv", index=False)

"""## Accuracy After Feature Engineering - PCA"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L2], y_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L2], y_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L2], y_pred,average='weighted')}")

"""# Label_3"""

clf = svm.SVC(kernel='linear', class_weight='balanced')
clf.fit(x_train[L3], y_train[L3])

y_pred = clf.predict(x_valid[L3])
y_pred_test_before = clf.predict(x_test[L3])

"""## Accuracy Before Feature Engineering"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L3], y_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L3], y_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L3], y_pred,average='weighted')}")

selector = SelectKBest(f_classif, k=15)
x_new = selector.fit_transform(x_train[L3], y_train[L3])
print(x_new.shape)

clf = svm.SVC(kernel='linear' )
clf.fit(x_new, y_train[L3])

y_new_pred = clf.predict(selector.transform(x_valid[L3]))

"""## Accuracy After Feature Engineering - selectKBest"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L3], y_new_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L3], y_new_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L3], y_pred,average='weighted')}")

pca = PCA(n_components = 0.45, svd_solver ='full')
pca.fit(x_train[L3])
x_train_trans = pd.DataFrame(pca.transform(x_train[L3]))
x_valid_trans = pd.DataFrame(pca.transform(x_valid[L3]))
x_test_pca = pca.transform(x_test[L3])

print(x_train_trans.shape, x_valid_trans.shape)

clf = svm.SVC(kernel='linear' )
clf.fit(x_train_trans, y_train[L3])

y_new_trans = clf.predict(x_valid_trans)

y_pred_test_after = clf.predict(x_test_pca)
print('Predicted labels after feature engineering:', y_pred_test_after)

output_df = pd.DataFrame({
    'Predicted labels before feature engineering': y_pred_test_before,
    'Predicted labels after feature engineering': y_pred_test_after,
    'No. of new features': x_test_pca.shape[1]
})


for i in range(x_test_pca.shape[1]):
  output_df[f'New feature {i+1}'] = x_test_pca[:, i]

output_df.head()

# Save the DataFrame to the specified CSV file path
output_df.to_csv(f"190394R_label_3.csv", index=False)

"""Accuracy After Feature Engineering - PCA"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L3], y_new_trans)}")
print(f"Precision: {metrics.precision_score(y_valid[L3], y_new_trans, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L3], y_new_trans,average='weighted')}")

"""# Label_4"""

k = 5  # Number of neighbors
knn_classifier4 = KNeighborsClassifier(n_neighbors=k)

knn_classifier4.fit(x_train[L4], y_train[L4])

y_pred = knn_classifier4.predict(x_valid[L4])
y_pred_test_before = knn_classifier4.predict(x_test[L4])

"""## Accuracy Before Feature Engineering"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L4], y_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L4], y_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L4], y_pred,average='weighted')}")

pca = PCA(n_components = 0.85, svd_solver ='full')
pca.fit(x_train[L4])
x_train_trans = pd.DataFrame(pca.transform(x_train[L4]))
x_valid_trans = pd.DataFrame(pca.transform(x_valid[L4]))
x_test_pca = pca.transform(x_test[L4])

print(x_train_trans.shape, x_valid_trans.shape)

knn_classifier4.fit(x_train_trans, y_train[L4])

y_pred = knn_classifier4.predict(x_valid_trans)

y_pred_test_after = knn_classifier4.predict(x_test_pca)
print('Predicted labels after feature engineering:', y_pred_test_after)

output_df = pd.DataFrame({
    'Predicted labels before feature engineering': y_pred_test_before,
    'Predicted labels after feature engineering': y_pred_test_after,
    'No. of new features': x_test_pca.shape[1]
})


for i in range(x_test_pca.shape[1]):
  output_df[f'New feature {i+1}'] = x_test_pca[:, i]

output_df.head()

# Save the DataFrame to the specified CSV file path
output_df.to_csv(f"190394R_label_4.csv", index=False)

y_pred_test_after = knn_classifier4.predict(x_test_pca)

"""Accuracy After Feature Engineering - PCA"""

print(f"Accuracy: {metrics.accuracy_score(y_valid[L4], y_pred)}")
print(f"Precision: {metrics.precision_score(y_valid[L4], y_pred, average='weighted')}")
print(f"Recall: {metrics.recall_score(y_valid[L4], y_pred,average='weighted')}")